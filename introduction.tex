\section{Introduction}
In recent years, there has been a noticeable trend for businesses and enterprises to migrate services such as online searches and online games to cloud environments \cite{yao2022hlb}. This shift has driven the deployment of massive data centers to meet the growing demand for cloud services. However, simply providing the abundant link and server resources \cite{greenberg2009vl2} is no longer sufficient to meet the rapidly growing user needs. It can even be counterproductive if incoming traffic is not allocated resources adequately for processing. Recognizing the need for more reliable and scalable services, operators have begun to deploy load balancing mechanisms within data centers. For instance, a Layer-4 load balancer (L4 LB) ensures that incoming traffic is distributed fairly across all reachable backend servers (DIPs). The goal of L4 LB is to maximize resource utilization to meet the growing needs of the business.

Approximately half of data center traffic requires L4 LB for processing \cite{patel2013ananta}.  Inefficient handling of this traffic by L4 LB can have severe consequences for the data center. Potential outcomes include some servers being underutilized, resulting in resource wastage, while others become overloaded, leading to downtime or even service interruptions. These issues can further cause a sharp decline in user experience \cite{miao2017silkroad}. Therefore, in Layer-4 load balancing, fairness should be treated as a first-class citizen.

Effective management of incoming traffic by L4 LB encounters two significant challenges. The first challenge arises from skewed traffic distribution. Applications commonly utilize short connections for synchronization and long connections for massive data transfer, resulting in a long-tail distribution where a few flows carry the majority of the traffic \cite{zeng2022tiara}. Improper handling of L4 LB in such scenarios can easily lead to uneven load distribution among servers \cite{aghdai2020spotlight}. The second challenge stems from the limitations imposed by L4 LB when dealing with stateful protocols, such as TCP and QUIC \cite{langley2017quic}. These protocols are usually connection-oriented to improve communication reliability. Consequently, all packets of a flow must be processed by the same server to maintain \emph{per-connection-consistency} (PCC) \cite{miao2017silkroad}. PCC violations can cause connection interruptions and increase the end-to-end delay during connection re-establishment, significantly impacting service quality. To address these challenges, previous works have focused on maintaining PCC \cite{eisenbud2016maglev, olteanu2018stateless, gandhi2014duet, araujo2018balancing}. However, some studies have revealed that these schemes often reduce PCC violations at the expense of load distribution fairness \cite{barbette2021cheetah}, contradicting the fundamental purpose of L4 LB.


In general, LB primarily enhances fairness in two main ways. The first method involves adjusting the scheduling granularity, commonly utilized in L3 LB \cite{aghdai2020spotlight}. Operators often use flowlet-level \cite{alizadeh2014conga, katta2016hula, liu2023burstbalancer} or packet-level \cite{perry2014fastpass} granularity to improve fairness. However, in L4 LB, since all packets of the same connection must be forwarded to the same server to maintain PCC, the granularity is limited to the flow-level. The second approach is to choose different scheduling methods, such as hashing \cite{miao2017silkroad, gandhi2014duet}, round-robin \cite{katta2016clove, he2015presto}, the least congestion \cite{alizadeh2014conga, curtis2011mahout}, and so on. However, because of PCC limitations, L4 LB must maintain the mapping between flows and servers in dynamic network environments \cite{araujo2018balancing}.
Consequently, existing solutions typically rely on hashing, which is usually difficult to achieve good fairness, or requires modifications to the TCP/IP protocol stack in terminal devices to select other advanced scheduling methods. Although the latter can bring better fairness, it often has poor scalability and is difficult to deploy directly in existing data centers.

Based on the above discussion, we believe that L4 LB should meet the following requirements: 1) \textbf{Fairness}: fully utilize the available resources of all servers; 2) \textbf{PCC}: packets belonging to the same connection are forwarded to the same server; 3) \textbf{Scalability}: no changes to the end host or protocol stack during deployment. To achieve these goals, this paper proposes Maat, an L4 LB implemented on a programmable switch. Maat proposes a novel scheduling method termed the power of one random choice. Specifically, to enhance fairness, Maat processes each flow by selecting one of two servers for forwarding, with one server selected through hashing to maintain PCC. To further improve fairness, Maat also employs a finer-grained approach to capture and analyze the status information of incoming traffic directly, making the selection more accurate.

Using the power of one random choice while always maintaining PCC on Maat is challenging. To address PCC violations caused by DIP pool updates (i.e., removal or additional of servers), we adopt Othello hashing, a minimum perfect hash \cite{majewski1996family}, as our hashing function for server selection. It is typically used for load balancing with low memory overhead and no false hits \cite{yu2018memory}. Additionally, the power of one random choice also cause PCC violations due to random selection. We transform this problem into a membership set problem and introduce a counting Bloom filter\cite{bonomi2006improved} to ensure PCC. By cleverly combining Othello hashing with counting Bloom filters, Maat can fully guarantee PCC with negligible memory even under heavy load.


To summarize, the key contributions of Maat are as follows:
\begin{itemize}
	\item We show that existing scheduling methods often face a dilemma: they either sacrifice fairness to guarantee PCC or cannot be directly deployed in contemporary data centers. Consequently, we propose a novel scheduling method named power of one random choice, capable of satisfying the requirements of L4 LB for both fairness and PCC simultaneously.
	\item We design and implement Maat, an LB that meets the two key requirements of L4 LB. Maat is easy to implement in programmable hardware (e.g., Tofino switch \cite{barefoot2019}) and can be deployed without any changes to the end host or TCP/IP protocol stack.
	\item We evaluate Maat extensively in hardware testbed and conduct simulations in scenarios with realistic traffic patterns. Our experimental results show that Maat achieves significant improvement in fairness by 70-80\% compared to existing L4 LB under heavy load.
\end{itemize}

In \S II of this paper, we first summarize the advantages and disadvantages of previous L4 LB related work, then introduce the design motivation behind Maat, and finally, we present some background algorithms. Subsequently, we introduce the overall architecture and design details of Maat in \S III. Next, the implementation and experimental results of Maat are described in \S IV, and finally, we conclude Maat in \S V.